{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a real-time inferencing ML Service \n",
    "(implemented with Azure Python SDK in VS Code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, make sure that \n",
    "- Python 3.7.8 is installed (some troubles can appear with later editions)\n",
    "- Install following VS Code Extensions: Python(IntelliSence(Pylance)), Azure Tools, Azure Machine Learning\n",
    "\n",
    "- Install following packages in powershell: \n",
    "pip install pandas\n",
    "pip install joblib\n",
    "pip install scikit-learn\n",
    "pip install azureml-core\n",
    "pip install azure-ai-ml\n",
    "pip install azureml-dataprep\n",
    "pip install azureml-widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (importlib-metadata 5.1.0 (c:\\users\\winpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages), Requirement.parse('importlib-metadata<5,>=0.23; python_version == \"3.7\"'), {'argcomplete'}).\n",
      "UserWarning: The resource group doesn't exist or was not provided. AzureML SDK is creating a resource group=aml-resources in location=eastus using subscription=1d702fb9-2f61-4de9-94be-1fff9c158887.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying AppInsights with name amlworksinsights54256b10.\n",
      "Deployed AppInsights with name amlworksinsights54256b10. Took 5.08 seconds.\n",
      "Deploying KeyVault with name amlworkskeyvaultf1fa1ae2.\n",
      "Deploying StorageAccount with name amlworksstorage7a0082bc4.\n",
      "Deployed KeyVault with name amlworkskeyvaultf1fa1ae2. Took 20.31 seconds.\n",
      "Deployed StorageAccount with name amlworksstorage7a0082bc4. Took 26.24 seconds.\n",
      "Deploying Workspace with name aml-workspace.\n",
      "Deployed Workspace with name aml-workspace. Took 24.97 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Creating workspace\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.create(name='aml-workspace', \n",
    "                    subscription_id='1d702fb9-2f61-4de9-94be-1fff9c158887',\n",
    "                    resource_group='aml-resources',\n",
    "                    create_resource_group=True,\n",
    "                    location='eastus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.48.0 to work with aml-workspace\n"
     ]
    }
   ],
   "source": [
    "#check if created and ready to use\n",
    "print(\"Ready to use Azure ML {} to work with {}\".format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Resources:\n"
     ]
    }
   ],
   "source": [
    "# use the following code to enumerate the compute resources in your workspace\n",
    "print(\"Compute Resources:\")\n",
    "for compute_name in ws.compute_targets:\n",
    "    compute = ws.compute_targets[compute_name]\n",
    "    print(\"\\t\", compute.name, ':', compute.type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create compute target\n",
    "We'll need a compute context for the pipeline, so we'll use the following code to specify an Azure Machine Learning compute cluster. Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress.\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"compute-cluster111\"\n",
    "try: \n",
    "    #check for existing compute target\n",
    "    inference_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    #if it doesn't already exist, create it\n",
    "    try: \n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        inference_cluster=ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        inference_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Resources:\n",
      "\t compute-cluster111 : AmlCompute\n"
     ]
    }
   ],
   "source": [
    "#check available compute targets again\n",
    "print(\"Compute Resources:\")\n",
    "for compute_name in ws.compute_targets:\n",
    "    compute = ws.compute_targets[compute_name]\n",
    "    print(\"\\t\", compute.name, ':', compute.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Uploading file to diabetes-data/\n",
      "Uploading an estimated of 2 files\n",
      "Uploading C:/Users/winpr/AzureML_Classification_PythonSDK/data\\diabetes2.csv\n",
      "Uploaded C:/Users/winpr/AzureML_Classification_PythonSDK/data\\diabetes2.csv, 1 files out of an estimated total of 2\n",
      "Uploading C:/Users/winpr/AzureML_Classification_PythonSDK/data\\diabetes.csv\n",
      "Uploaded C:/Users/winpr/AzureML_Classification_PythonSDK/data\\diabetes.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n",
      "Creating new dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', '/diabetes-data/')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the data to datastore (remember Datastore - is just a connection to your real data)\n",
    "from azureml.core import Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "\n",
    "default_ds= ws.get_default_datastore()\n",
    "Dataset.File.upload_directory(src_dir='C:/Users/winpr/AzureML_Classification_PythonSDK/data', target=DataPath(default_ds, 'diabetes-data/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\winpr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\azureml\\dataprep\\api\\_dataframereader.py:461: UserWarning: Please install pyarrow>=0.16.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install pyarrow>=0.16.0 --upgrade\n",
      "  \"Please install pyarrow>=0.16.0 for improved performance of to_pandas_dataframe. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>PlasmaGlucose</th>\n",
       "      <th>DiastolicBloodPressure</th>\n",
       "      <th>TricepsThickness</th>\n",
       "      <th>SerumInsulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1354778</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>43.509726</td>\n",
       "      <td>1.213191</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1147438</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>21.240576</td>\n",
       "      <td>0.158365</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1640031</td>\n",
       "      <td>7</td>\n",
       "      <td>115</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>41.511523</td>\n",
       "      <td>0.079019</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1883350</td>\n",
       "      <td>9</td>\n",
       "      <td>103</td>\n",
       "      <td>78</td>\n",
       "      <td>25</td>\n",
       "      <td>304</td>\n",
       "      <td>29.582192</td>\n",
       "      <td>1.282870</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1424119</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>42.604536</td>\n",
       "      <td>0.549542</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  Pregnancies  PlasmaGlucose  DiastolicBloodPressure  \\\n",
       "0    1354778            0            171                      80   \n",
       "1    1147438            8             92                      93   \n",
       "2    1640031            7            115                      47   \n",
       "3    1883350            9            103                      78   \n",
       "4    1424119            1             85                      59   \n",
       "\n",
       "   TricepsThickness  SerumInsulin        BMI  DiabetesPedigree  Age  Diabetic  \n",
       "0                34            23  43.509726          1.213191   21         0  \n",
       "1                47            36  21.240576          0.158365   23         0  \n",
       "2                52            35  41.511523          0.079019   23         0  \n",
       "3                25           304  29.582192          1.282870   43         1  \n",
       "4                27            35  42.604536          0.549542   22         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tabular dataset\n",
    "from azureml.core import Dataset\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'), header=True)\n",
    "\n",
    "# display the first 20 rows\n",
    "tab_data_set.take(5).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register dataset in AzureML Workspace\n",
    "try:\n",
    "    tab_data_set = tab_data_set.register(workspace=ws,name= 'diabetes file dataset',description='diabetes files',tags={'format':'CSV'}, create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here to avoid snapshot error had to configure experiment.start_logging(snapshot_directory=None)\n",
    "https://learn.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment(class)?view=azure-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: mslearn-train-diabetes\n",
      "Loading Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\winpr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\azureml\\dataprep\\api\\_dataframereader.py:461: UserWarning: Please install pyarrow>=0.16.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install pyarrow>=0.16.0 --upgrade\n",
      "  \"Please install pyarrow>=0.16.0 for improved performance of to_pandas_dataframe. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a decision tree model\n",
      "Accuracy: 0.8966666666666666\n",
      "AUC: 0.8812731098273671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\winpr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:36: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "C:\\Users\\winpr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:42: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and registered\n"
     ]
    }
   ],
   "source": [
    "# Train and register the sklearn DecisionTreeClassifier model\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#Create AzureML experiment in your workspace\n",
    "experiment= Experiment(workspace=ws, name=\"mslearn-train-diabetes\")\n",
    "run = experiment.start_logging(snapshot_directory=None) # to avoid snapshot error\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "#Load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "#diabetes = pd.read_csv(tab_data_set)\n",
    "diabetes = tab_data_set.to_pandas_dataframe()\n",
    "\n",
    "#Separate features and labels\n",
    "X,y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=0)\n",
    "\n",
    "#Train a desicion tree model\n",
    "print(\"Training a decision tree model\")\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "#calculate accuracy\n",
    "y_hat= model.predict(X_test)\n",
    "acc= np.average(y_hat==y_test)\n",
    "print(\"Accuracy:\", acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "#calculate AUC\n",
    "y_scores= model.predict_proba(X_test)\n",
    "auc= roc_auc_score(y_test, y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "#Save the trained model. The best option to keep all the data in project directory\n",
    "model_file= 'diabetes_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "run.upload_file(name='AzureML_Classification_PythonSDK/outputs/' + model_file, path_or_stream= './' + model_file)\n",
    "\n",
    "#Complete the run\n",
    "run.complete()\n",
    "\n",
    "#Register the model\n",
    "run.register_model(model_path='AzureML_Classification_PythonSDK/outputs/diabetes_model.pkl', model_name='diabetes_model',tags={'Training context':'Inline Training'}, properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "print(\"Model trained and registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model as a web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version: 1\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8812731098273671\n",
      "\t Accuracy : 0.8966666666666666\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loop through available models\n",
    "\n",
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag= model.tags[tag_name]\n",
    "        print('\\t', tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop=model.properties[prop_name]\n",
    "        print('\\t', prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version 1\n"
     ]
    }
   ],
   "source": [
    "# et the model that we want to deploy\n",
    "model = ws.models['diabetes_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to create a web service to host this model, and this will require some code and configuration files; so let's create a folder for those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureML_Classification_PythonSDK/diabetes_service folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the deployment files\n",
    "#deployment_folder= './diabetes_service'  - to deploy in default wd\n",
    "#deploy to project directory : \n",
    "\n",
    "# deploy to project folder 'C:/Users/winpr/AzureML_Classification_PythonSDK/\n",
    "deployment_folder= 'AzureML_Classification_PythonSDK/diabetes_service'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "print(deployment_folder, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = 'score_diabetes.py'\n",
    "script_path = os.path.join(deployment_folder, script_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web service where we deploy the model will need some Python code to load the input data, get the model from the workspace, and generate and return predictions. We'll save this code in an entry script (often called a scoring script) that will be deployed to the web service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remember to place %% magic functions at the begining of code cell (no #comments before %% allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing AzureML_Classification_PythonSDK/diabetes_service\\score_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'diabetes_model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "#Called when a request is received\n",
    "def run(raw_data):\n",
    "    #Get the input data as a numpy array\n",
    "    data= np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web service will be hosted in a container, and the container will need to install any required Python dependencies when it gets initialized. In this case, our scoring code requires scikit-learn and some Azure Machine Learning specific packages that are used by the scoring web service, so we'll create an environment that included these. Then we'll add that environment to an inference configuration along with the scoring script, and define a deployment configuration for the container in which the environment and script will be hosted.\n",
    "We can then deploy the model as a service based on these configurations.\n",
    "\n",
    "    More Information: For more details about model deployment, and options for target execution environments, see the documentation.\n",
    "    https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-online-endpoints?tabs=azure-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\winpr\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:22: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration. \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-12-20 11:14:11+01:00 Creating Container Registry if not exists..\n",
      "2022-12-20 11:24:12+01:00 Registering the environment.\n",
      "2022-12-20 11:24:13+01:00 Use the existing image.\n",
      "2022-12-20 11:24:13+01:00 Generating deployment configuration.\n",
      "2022-12-20 11:24:14+01:00 Submitting deployment to compute..\n",
      "2022-12-20 11:24:19+01:00 Checking the status of deployment diabetes-service..\n",
      "2022-12-20 11:25:52+01:00 Checking the status of inference endpoint diabetes-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "# Deployment can take up to 30 min to create a container image, and then runs a process to create a web service \n",
    "# based on the image. \n",
    "# When deployment has completed successfully, you'll see a status of Healthy.\n",
    "\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "# Configure the scoring environment\n",
    "# here \"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\" - specific configuration\n",
    "service_env= Environment.get(workspace=ws, name= \"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\")\n",
    "service_env.inferencing_stack_version= \"latest\"\n",
    "\n",
    "inference_config = InferenceConfig(source_directory = deployment_folder, entry_script=script_file, environment = service_env)\n",
    "\n",
    "# Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb =1)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print ('Deploying model...')\n",
    "service_name = \"diabetes-service\"\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite = True)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-20T10:25:46,408621200+00:00 - nginx/run \n",
      "2022-12-20T10:25:46,409664400+00:00 - gunicorn/run \n",
      "2022-12-20T10:25:46,415225000+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:46,417288600+00:00 | gunicorn/run | ###############################################\n",
      "2022-12-20T10:25:46,423421200+00:00 | gunicorn/run | AzureML Container Runtime Information\n",
      "2022-12-20T10:25:46,426348100+00:00 | gunicorn/run | ###############################################\n",
      "2022-12-20T10:25:46,430914000+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:46,433430200+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:46,442497500+00:00 | gunicorn/run | AzureML image information: sklearn-0.24.1-ubuntu18.04-py37-cpu-inference:20221024.v1\n",
      "2022-12-20T10:25:46,446803900+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:46,448483200+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:46,449975500+00:00 | gunicorn/run | PATH environment variable: /opt/miniconda/envs/amlenv/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "2022-12-20T10:25:46,455547800+00:00 | gunicorn/run | PYTHONPATH environment variable: \n",
      "2022-12-20T10:25:46,457032200+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:49,257693900+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n",
      "\n",
      "# conda environments:\n",
      "#\n",
      "base                  *  /opt/miniconda\n",
      "amlenv                   /opt/miniconda/envs/amlenv\n",
      "\n",
      "2022-12-20T10:25:50,001698000+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:50,004632700+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n",
      "\n",
      "azure-core==1.26.0\n",
      "azure-identity==1.11.0\n",
      "azureml-inference-server-http==0.7.6\n",
      "cachetools==5.2.0\n",
      "certifi==2022.9.24\n",
      "cffi==1.15.1\n",
      "charset-normalizer==2.1.1\n",
      "click==8.1.3\n",
      "cryptography==38.0.1\n",
      "Flask==2.1.3\n",
      "Flask-Cors==3.0.10\n",
      "google-api-core==2.10.2\n",
      "google-auth==2.13.0\n",
      "googleapis-common-protos==1.56.4\n",
      "gunicorn==20.1.0\n",
      "idna==3.4\n",
      "importlib-metadata==5.0.0\n",
      "inference-schema==1.4.2.1\n",
      "itsdangerous==2.1.2\n",
      "Jinja2==3.1.2\n",
      "joblib==1.2.0\n",
      "MarkupSafe==2.1.1\n",
      "msal==1.20.0\n",
      "msal-extensions==1.0.0\n",
      "numpy==1.21.6\n",
      "opencensus==0.11.0\n",
      "opencensus-context==0.1.3\n",
      "opencensus-ext-azure==1.1.7\n",
      "pandas==1.1.5\n",
      "portalocker==2.6.0\n",
      "protobuf==4.21.8\n",
      "psutil==5.9.3\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycparser==2.21\n",
      "PyJWT==2.6.0\n",
      "python-dateutil==2.8.2\n",
      "pytz==2022.5\n",
      "requests==2.28.1\n",
      "rsa==4.9\n",
      "scikit-learn==0.24.1\n",
      "scipy==1.7.3\n",
      "six==1.16.0\n",
      "threadpoolctl==3.1.0\n",
      "typing-extensions==4.4.0\n",
      "urllib3==1.26.12\n",
      "Werkzeug==2.2.2\n",
      "wrapt==1.12.1\n",
      "zipp==3.10.0\n",
      "\n",
      "2022-12-20T10:25:52,009781000+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:52,011665200+00:00 | gunicorn/run | Entry script directory: /var/azureml-app\n",
      "2022-12-20T10:25:52,018036100+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:52,020422700+00:00 | gunicorn/run | ###############################################\n",
      "2022-12-20T10:25:52,022646500+00:00 | gunicorn/run | Dynamic Python Package Installation\n",
      "2022-12-20T10:25:52,027730600+00:00 | gunicorn/run | ###############################################\n",
      "2022-12-20T10:25:52,029712100+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:52,032041300+00:00 | gunicorn/run | Dynamic Python package installation is disabled.\n",
      "2022-12-20T10:25:52,037675800+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:52,040682600+00:00 | gunicorn/run | ###############################################\n",
      "2022-12-20T10:25:52,046747500+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n",
      "2022-12-20T10:25:52,049229500+00:00 | gunicorn/run | ###############################################\n",
      "2022-12-20T10:25:52,051248900+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:52,971796900+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:52,974421400+00:00 | gunicorn/run | ###############################################\n",
      "2022-12-20T10:25:52,980639300+00:00 | gunicorn/run | AzureML Inference Server\n",
      "2022-12-20T10:25:52,983833900+00:00 | gunicorn/run | ###############################################\n",
      "2022-12-20T10:25:52,987304600+00:00 | gunicorn/run | \n",
      "2022-12-20T10:25:52,992956000+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n",
      "\n",
      "Azure ML Inferencing HTTP server v0.7.6\n",
      "\n",
      "\n",
      "Server Settings\n",
      "---------------\n",
      "Entry Script Name: /var/azureml-app/main.py\n",
      "Model Directory: /var/azureml-app/azureml-models/diabetes_model/1\n",
      "Worker Count: 1\n",
      "Worker Timeout (seconds): 300\n",
      "Server Port: 31311\n",
      "Application Insights Enabled: false\n",
      "Application Insights Key: None\n",
      "Inferencing HTTP server version: azmlinfsrv/0.7.6\n",
      "CORS for the specified origins: None\n",
      "\n",
      "\n",
      "Server Routes\n",
      "---------------\n",
      "Liveness Probe: GET   127.0.0.1:31311/\n",
      "Score:          POST  127.0.0.1:31311/score\n",
      "\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://0.0.0.0:31311 (73)\n",
      "Using worker: sync\n",
      "Booting worker with pid: 128\n",
      "Initializing logger\n",
      "2022-12-20 10:25:55,777 | root | INFO | Starting up app insights client\n",
      "logging socket not found. logging not available.\n",
      "logging socket not found. logging not available.\n",
      "2022-12-20 10:25:55,778 | root | INFO | Starting up app insight hooks\n",
      "2022-12-20 10:25:56,803 | root | INFO | Found driver script at /var/azureml-app/main.py and the score script at /var/azureml-app/diabetes_service/score_diabetes.py\n",
      "2022-12-20 10:25:56,803 | root | INFO | run() is not decorated. Server will invoke it with the input in JSON string.\n",
      "2022-12-20 10:25:56,804 | root | INFO | Invoking user's init function\n",
      "00000000-0000-0000-0000-000000000000,/opt/miniconda/envs/amlenv/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "2022-12-20 10:25:58,992 | root | INFO | Users's init has completed successfully\n",
      "2022-12-20 10:25:58,994 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\n",
      "2022-12-20 10:25:58,996 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2022-12-20 10:25:59,000 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\n",
      "2022-12-20 10:28:44,764 | root | INFO | 200\n",
      "127.0.0.1 - - [20/Dec/2022:10:28:44 +0000] \"GET /swagger.json HTTP/1.0\" 200 2265 \"-\" \"Go-http-client/1.1\"\n",
      "2022-12-20 10:28:49,019 | root | INFO | 200\n",
      "127.0.0.1 - - [20/Dec/2022:10:28:49 +0000] \"GET /swagger.json HTTP/1.0\" 200 2265 \"-\" \"Go-http-client/1.1\"\n",
      "2022-12-20 10:30:55,045 | root | INFO | 200\n",
      "127.0.0.1 - - [20/Dec/2022:10:30:55 +0000] \"GET /swagger.json HTTP/1.0\" 200 2265 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hopefully, the deployment has been successful and you can see a status of Healthy. \n",
    "# If not, you can use the following code to get the service logs to help you troubleshoot.\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to make a change and redeploy, you may need to delete unhealthy service using the following code:\n",
    "#service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes-service\n"
     ]
    }
   ],
   "source": [
    "# You can also retrieve the names of web services in your workspace by running the following code:\n",
    "for webservice_name in ws.webservices:\n",
    "    print(webservice_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the web service\n",
    "\n",
    "With the service deployed, now you can consume it from a client application to make a prediction on the new data provided to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22]\n",
      "diabetic\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# provide new feature data\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
    "print ('Patient: {}'.format(x_new[0]))\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "predicted_classes = json.loads(predictions)\n",
    "print(predicted_classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] diabetic\n",
      "Patient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] not-diabetic\n"
     ]
    }
   ],
   "source": [
    "# You can also send multiple patient observations to the service, and get back a prediction for each one.\n",
    "import json\n",
    "\n",
    "# This time our input is an array of two feature arrays\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array or arrays to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted classes.\n",
    "predicted_classes = json.loads(predictions)\n",
    "   \n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above uses the Azure Machine Learning SDK to connect to the containerized web service and use it to generate predictions from your diabetes classification model. In production, a model is likely to be consumed by business applications that do not use the Azure Machine Learning SDK, but simply make HTTP requests to the web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://2a2b6b15-2484-4e94-8300-369f8b087c19.eastus.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "#Let's determine the URL to which these applications must submit their requests:\n",
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know the endpoint URI, an application can simply make an HTTP request, sending the patient data in JSON format, and receive back the predicted class(es)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] diabetic\n",
      "Patient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] not-diabetic\n"
     ]
    }
   ],
   "source": [
    "# make HTTP request containing new data for prediction\n",
    "import requests\n",
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've deployed your web service as an Azure Container Instance (ACI) service that requires no authentication. This is fine for development and testing, but for production you should consider deploying to an Azure Kubernetes Service (AKS) cluster and enabling token-based authentication. This would require REST requests to include an Authorization header."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the service to avoid incurring unecessary charges.\n",
    "\n",
    "service.delete()\n",
    "print ('Service deleted.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1da407c247b4ad945211ad48740e66b0f7eb0815cb7b0c928c3e040c061e316"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
